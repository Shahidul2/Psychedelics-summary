{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a18d2442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports done.\n"
     ]
    }
   ],
   "source": [
    "# === 1) IMPORTS ===\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from spacy.util import filter_spans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import MedianPruner\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "print(\"Imports done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85322f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpaCy model loaded.\n",
      "326 stopwords loaded.\n"
     ]
    }
   ],
   "source": [
    "# === 2) EXPERIENTIAL TERMS & SPACY LOADING ===\n",
    "\n",
    "# Experiential terms\n",
    "experiential_terms = {\n",
    "    'emotional': [\n",
    "        'felt','feeling','emotion','joy','fear','anxiety','bliss','love','terror','peace','calm',\n",
    "        'excited','overwhelmed','gratitude','euphoria','sadness','longing','crying','ecstasy','relief',\n",
    "        'compassion','grief','awe','anger','release','hope','despair','serenity','agitation','comfort',\n",
    "        'purging','vulnerability','intimacy','empathy','tension','melancholy','abandon','appreciation'\n",
    "    ],\n",
    "    'sensory': [\n",
    "        'visual','hear','sound','color','bright','pattern','geometry','music','taste','smell','see',\n",
    "        'saw','colors','sounds','shapes','textures','movement','melting','vibrations','pulsing',\n",
    "        'fractal','echo','flashing','tunnel','fluid','shimmering','sparkling','synesthesia',\n",
    "        'auditory','trails','glow','hallucination','pulsate','distortion','radiance','static',\n",
    "        'blurred','lightness','glimmer','resonance','tactile','kaleidoscopic'\n",
    "    ],\n",
    "    'cognitive': [\n",
    "        'thought','mind','consciousness','aware','realize','understand','insight','clarity','confused',\n",
    "        'clear','thinking','perception','concepts','identity','ego','dissolve','looping','logic',\n",
    "        'recognition','belief','interpretation','memory','language','narrative','meaning','mindspace',\n",
    "        'headspace','overthinking','mental','clarification','self-talk','rational','intellect',\n",
    "        'philosophical','metacognition','rumination','stream of consciousness','inner dialogue',\n",
    "        'cognitive dissonance','hyperfocus'\n",
    "    ],\n",
    "    'physical': [\n",
    "        'body','skin','breath','heart','energy','vibration','tingling','warm','heavy','light','pressure',\n",
    "        'sensation','nausea','shaking','sweating','floating','stillness','tightness','spasm','motion',\n",
    "        'trembling','cold','breathing','heartbeat','twitching','dry mouth','muscles','stiffness',\n",
    "        'paralysis','numbness','restlessness','chills','sweat','clenching','somatic','bodyload',\n",
    "        'temperature','digestive','physical release'\n",
    "    ],\n",
    "    'mystical': [\n",
    "        'ego','self','unity','divine','spiritual','transcend','infinite','oneness','god','universe',\n",
    "        'connected','sacred','eternal','death','rebirth','timeless','interconnected','presence','source',\n",
    "        'void','light','beyond','higher power','awakening','realm','dimension','truth','immortality',\n",
    "        'ego death','no-self','nirvana','cosmic','transcendence','pure being','karma','light being',\n",
    "        'soul','heaven','angelic','time distortion','godlike','divinity','portal','third eye',\n",
    "        'nondual','dissolution','samsara','infinity','entity','timelessness'\n",
    "    ],\n",
    "    'temporal': [\n",
    "        'onset','peak','comedown','duration','timeline','hours','minutes','start','beginning',\n",
    "        'after','later','build-up','before','end','wave','early','gradual','suddenly',\n",
    "        'phase','stage','passed','elapsed','over time','rush','fade','linger','moment',\n",
    "        'slowly','time passed','time distorted','hour mark','entry','exit'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Flatten\n",
    "EXP_TERMS_FLAT = {word.lower() for words in experiential_terms.values() for word in words}\n",
    "\n",
    "# Load SpaCy + stopwords\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\", disable=[\"tagger\", \"parser\", \"lemmatizer\", \"ner\"])\n",
    "    if \"senter\" not in nlp.pipe_names:\n",
    "        nlp.add_pipe(\"sentencizer\")\n",
    "    print(\"SpaCy model loaded.\")\n",
    "except OSError:\n",
    "    raise RuntimeError(\"SpaCy model not found. Run: python -m spacy download en_core_web_sm\")\n",
    "\n",
    "# Define stopwords\n",
    "from spacy.lang.en.stop_words import STOP_WORDS as SPACY_STOPWORDS\n",
    "print(f\"{len(SPACY_STOPWORDS)} stopwords loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fe06b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 3) TEXT CLEANING & SENTENCIZATION (No NER, Lowercase Early) ===\n",
    "\n",
    "_whitespace_re = re.compile(r\"[ \\t\\v\\f]+\")\n",
    "_newlines_re   = re.compile(r\"\\s*\\n\\s*\")\n",
    "\n",
    "def clean_text_basic(txt: str) -> str:\n",
    "    \"\"\"Lowercase and clean whitespace.\"\"\"\n",
    "    if not isinstance(txt, str) or pd.isna(txt):\n",
    "        return \"\"\n",
    "    txt = txt.lower()  # âœ… Lowercase early\n",
    "    txt = txt.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "    txt = _newlines_re.sub(\"\\n\", txt)\n",
    "    txt = _whitespace_re.sub(\" \", txt).strip()\n",
    "    return txt\n",
    "\n",
    "def sentencize_and_clean(raw_text: str, nlp, remove_sw_for_graph=True, remove_sw_for_summary=False):\n",
    "    \"\"\"Split into sentences. All text is lowercased.\"\"\"\n",
    "    raw_text_clean = clean_text_basic(raw_text)\n",
    "    doc = nlp.make_doc(raw_text_clean)\n",
    "\n",
    "    # Segment sentences\n",
    "    if \"senter\" in nlp.pipe_names:\n",
    "        nlp.get_pipe(\"senter\")(doc)\n",
    "    else:\n",
    "        doc = nlp(raw_text_clean)\n",
    "\n",
    "    sents = [s.text.strip() for s in doc.sents if s.text.strip()]\n",
    "\n",
    "    def remove_stopwords(s):\n",
    "        d = nlp.make_doc(s)\n",
    "        tokens = [t.text for t in d if t.is_alpha and t.text not in SPACY_STOPWORDS]\n",
    "        return \" \".join(tokens).strip()\n",
    "\n",
    "    s_graph = [remove_stopwords(s) for s in sents] if remove_sw_for_graph else sents\n",
    "    s_summary = sents if not remove_sw_for_summary else [remove_stopwords(s) for s in sents]\n",
    "\n",
    "    return sents, s_graph, s_summary, raw_text_clean  # all lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e095b7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced subset: (300, 8)\n",
      "_subst_norm\n",
      "Psilocybin    100\n",
      "LSD           100\n",
      "DMT           100\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# === 4) LOAD DATA & BALANCED SUBSET ===\n",
    "\n",
    "DATA_PATH = Path(r\"final_train_900.csv\")\n",
    "if not DATA_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Missing: {DATA_PATH}\")\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "REQUIRED_COLS = {\"report_text\", \"substance\"}\n",
    "missing = REQUIRED_COLS - set(df.columns)\n",
    "if missing:\n",
    "    raise KeyError(f\"Missing columns: {missing}\")\n",
    "\n",
    "def _norm_sub(x):\n",
    "    if not isinstance(x, str): return \"OTHER\"\n",
    "    y = x.strip().upper()\n",
    "    if y in {\"DMT\"}: return \"DMT\"\n",
    "    if y in {\"LSD\", \"ACID\"}: return \"LSD\"\n",
    "    if y in {\"PSILOCYBIN\", \"PSILOCYBIN MUSHROOM\", \"MUSHROOM\", \"MUSHROOMS\", \"PSILOCYBE\"}:\n",
    "        return \"Psilocybin\"\n",
    "    return y\n",
    "\n",
    "df[\"_subst_norm\"] = df[\"substance\"].map(_norm_sub)\n",
    "TARGETS = [\"DMT\", \"LSD\", \"Psilocybin\"]\n",
    "N_PER_CLASS = 100\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "dfs = []\n",
    "for s in TARGETS:\n",
    "    pool = df[df[\"_subst_norm\"] == s]\n",
    "    n_pick = min(N_PER_CLASS, len(pool))\n",
    "    if n_pick < N_PER_CLASS:\n",
    "        print(f\" Only {n_pick} available for {s}\")\n",
    "    dfs.append(pool.sample(n=n_pick, random_state=RANDOM_SEED))\n",
    "\n",
    "df_sub = pd.concat(dfs, ignore_index=True).sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "print(f\"Balanced subset: {df_sub.shape}\")\n",
    "print(df_sub['_subst_norm'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bab0ff48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§  Precomputing sentences & similarity matrices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:18<00:00, 16.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputed: 300 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === 5) PRECOMPUTE SENTENCES + COSINE MATRICES ===\n",
    "\n",
    "def _precompute_doc(text, nlp):\n",
    "    sents, s_graph, s_summary, cleaned = sentencize_and_clean(\n",
    "        text, nlp,\n",
    "        remove_sw_for_graph=True,\n",
    "        remove_sw_for_summary=False\n",
    "    )\n",
    "    if len(sents) == 0:\n",
    "        return [], np.zeros((0,0), dtype=np.float32), cleaned\n",
    "\n",
    "    vec = TfidfVectorizer(lowercase=False,  \n",
    "                          stop_words=\"english\",\n",
    "                          max_features=4000)\n",
    "    X = vec.fit_transform(s_graph)\n",
    "    sim = cosine_similarity(X).astype(np.float32)\n",
    "    np.fill_diagonal(sim, 0.0)\n",
    "    return s_summary, sim, cleaned  # s_summary = original sentences (with stopwords, lowercase)\n",
    "\n",
    "print(\"ðŸ§  Precomputing sentences & similarity matrices...\")\n",
    "cache = []\n",
    "for text in tqdm(df_sub[\"report_text\"].astype(str).fillna(\"\"), total=len(df_sub)):\n",
    "    s_render, sim, cleaned = _precompute_doc(text, nlp)\n",
    "    cache.append({\n",
    "        \"s_render\": s_render,\n",
    "        \"sim\": sim,\n",
    "        \"doc_clean\": cleaned\n",
    "    })\n",
    "\n",
    "print(f\"Precomputed: {len(cache)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af9b79e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 6) FAST PAGE RANK & SUMMARY FROM CACHE ===\n",
    "\n",
    "def _pagerank(P: np.ndarray, damping: float = 0.85, eps: float = 1e-6, max_iter: int = 100) -> np.ndarray:\n",
    "    n = P.shape[0]\n",
    "    if n == 0:\n",
    "        return np.array([])\n",
    "    v = np.ones(n, dtype=np.float32) / n\n",
    "    teleport = np.ones(n, dtype=np.float32) / n\n",
    "    for _ in range(max_iter):\n",
    "        v_new = damping * P.T.dot(v) + (1 - damping) * teleport\n",
    "        if np.linalg.norm(v_new - v, ord=1) < eps:\n",
    "            return v_new\n",
    "        v = v_new\n",
    "    return v\n",
    "\n",
    "def _summary_from_cache(entry, compression_ratio: float, similarity_threshold: float, damping_factor: float):\n",
    "    s_render = entry[\"s_render\"]\n",
    "    sim = entry[\"sim\"]\n",
    "    if len(s_render) == 0 or sim.size == 0:\n",
    "        return \"\"\n",
    "\n",
    "    A = np.where(sim >= similarity_threshold, sim, 0.0).astype(np.float32)\n",
    "    row_sums = A.sum(axis=1, keepdims=True)\n",
    "    row_sums[row_sums == 0] = 1.0\n",
    "    P = A / row_sums\n",
    "\n",
    "    scores = _pagerank(P, damping=damping_factor)\n",
    "    k = max(1, int(round(len(s_render) * compression_ratio)))\n",
    "    top_idx = np.argsort(-scores)[:k]\n",
    "    return \" \".join(s_render[i] for i in sorted(top_idx)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "238fa1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 7) SCORING FUNCTIONS (No .lower() needed â€” all text is lowercase) ===\n",
    "\n",
    "def _tfidf_cosine(a: str, b: str) -> float:\n",
    "    if not a.strip() or not b.strip():\n",
    "        return 0.0\n",
    "    vec = TfidfVectorizer(lowercase=False, stop_words=\"english\", max_features=4000)\n",
    "    try:\n",
    "        X = vec.fit_transform([a, b])\n",
    "        return float(cosine_similarity(X[0], X[1])[0,0])\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "def score_semantic(summary: str, document: str) -> float:\n",
    "    return _tfidf_cosine(summary, document)\n",
    "\n",
    "def score_experiential(summary: str, document: str) -> float:\n",
    "    if not summary or not document:\n",
    "        return 0.0\n",
    "    doc_terms = {w for w in EXP_TERMS_FLAT if w in document}  # âœ… No .lower()!\n",
    "    if not doc_terms:\n",
    "        return 1.0\n",
    "    sum_terms = {w for w in EXP_TERMS_FLAT if w in summary}  # âœ… No .lower()!\n",
    "    return len(doc_terms & sum_terms) / len(doc_terms)\n",
    "\n",
    "def score_coherence(summary: str) -> float:\n",
    "    if not summary.strip():\n",
    "        return 0.0\n",
    "    sents = [s.strip() for s in re.split(r'(?<=[.!?])\\s+', summary) if s.strip()]\n",
    "    if len(sents) < 2:\n",
    "        return 1.0\n",
    "    vec = TfidfVectorizer(lowercase=False, stop_words=\"english\", max_features=4000)\n",
    "    try:\n",
    "        X = vec.fit_transform(sents)\n",
    "        sims = [float(cosine_similarity(X[i], X[i+1])[0,0]) for i in range(len(sents)-1)]\n",
    "        return float(np.mean(sims)) if sims else 0.0\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "def custom_score(summary: str, document: str) -> float:\n",
    "    if not summary or not document:\n",
    "        return 0.0\n",
    "    sem = score_semantic(summary, document)\n",
    "    exp = score_experiential(summary, document)\n",
    "    coh = score_coherence(summary)\n",
    "    return 0.5*sem + 0.3*exp + 0.2*coh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdcb76f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-10 21:20:20,307] A new study created in memory with name: LexRank_M1_cached_subset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning on 300 docs | Pruning every 25 docs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ac23fd44ca24b2ea3eecbde18748bd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-10 21:20:25,764] Trial 0 finished with value: 0.4285565307919664 and parameters: {'compression_ratio': 0.25, 'similarity_threshold': 0.15, 'damping_factor': 0.85}. Best is trial 0 with value: 0.4285565307919664.\n",
      "[I 2025-08-10 21:20:31,835] Trial 1 finished with value: 0.4498540462281225 and parameters: {'compression_ratio': 0.28, 'similarity_threshold': 0.15, 'damping_factor': 0.9}. Best is trial 1 with value: 0.4498540462281225.\n",
      "[I 2025-08-10 21:20:37,535] Trial 2 finished with value: 0.4107405257508243 and parameters: {'compression_ratio': 0.28, 'similarity_threshold': 0.35, 'damping_factor': 0.85}. Best is trial 1 with value: 0.4498540462281225.\n",
      "[I 2025-08-10 21:20:43,472] Trial 3 finished with value: 0.42813820900630123 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.35, 'damping_factor': 0.85}. Best is trial 1 with value: 0.4498540462281225.\n",
      "[I 2025-08-10 21:20:49,350] Trial 4 finished with value: 0.4234385439530432 and parameters: {'compression_ratio': 0.28, 'similarity_threshold': 0.25, 'damping_factor': 0.85}. Best is trial 1 with value: 0.4498540462281225.\n",
      "[I 2025-08-10 21:20:54,443] Trial 5 finished with value: 0.37868282963362493 and parameters: {'compression_ratio': 0.22, 'similarity_threshold': 0.25, 'damping_factor': 0.85}. Best is trial 1 with value: 0.4498540462281225.\n",
      "[I 2025-08-10 21:20:59,900] Trial 6 finished with value: 0.38573606225468743 and parameters: {'compression_ratio': 0.25, 'similarity_threshold': 0.35, 'damping_factor': 0.9}. Best is trial 1 with value: 0.4498540462281225.\n",
      "[I 2025-08-10 21:21:05,700] Trial 7 finished with value: 0.4107405257508243 and parameters: {'compression_ratio': 0.28, 'similarity_threshold': 0.35, 'damping_factor': 0.85}. Best is trial 1 with value: 0.4498540462281225.\n",
      "[I 2025-08-10 21:21:11,489] Trial 8 finished with value: 0.42775115972780603 and parameters: {'compression_ratio': 0.25, 'similarity_threshold': 0.15, 'damping_factor': 0.9}. Best is trial 1 with value: 0.4498540462281225.\n",
      "[I 2025-08-10 21:21:11,954] Trial 9 pruned. \n",
      "[I 2025-08-10 21:21:18,290] Trial 10 finished with value: 0.46308258734667807 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.9}. Best is trial 10 with value: 0.46308258734667807.\n",
      "[I 2025-08-10 21:21:24,761] Trial 11 finished with value: 0.46308258734667807 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.9}. Best is trial 10 with value: 0.46308258734667807.\n",
      "[I 2025-08-10 21:21:31,089] Trial 12 finished with value: 0.46308258734667807 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.9}. Best is trial 10 with value: 0.46308258734667807.\n",
      "[I 2025-08-10 21:21:37,450] Trial 13 finished with value: 0.46308258734667807 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.9}. Best is trial 10 with value: 0.46308258734667807.\n",
      "[I 2025-08-10 21:21:43,777] Trial 14 finished with value: 0.46308258734667807 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.9}. Best is trial 10 with value: 0.46308258734667807.\n",
      "[I 2025-08-10 21:21:50,159] Trial 15 finished with value: 0.46308258734667807 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.9}. Best is trial 10 with value: 0.46308258734667807.\n",
      "[I 2025-08-10 21:21:56,529] Trial 16 finished with value: 0.46308258734667807 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.9}. Best is trial 10 with value: 0.46308258734667807.\n",
      "[I 2025-08-10 21:22:02,959] Trial 17 finished with value: 0.46308258734667807 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.9}. Best is trial 10 with value: 0.46308258734667807.\n",
      "[I 2025-08-10 21:22:09,372] Trial 18 finished with value: 0.46308258734667807 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.9}. Best is trial 10 with value: 0.46308258734667807.\n",
      "[I 2025-08-10 21:22:09,857] Trial 19 pruned. \n",
      "[I 2025-08-10 21:22:16,349] Trial 20 finished with value: 0.46308258734667807 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.9}. Best is trial 10 with value: 0.46308258734667807.\n",
      "[I 2025-08-10 21:22:22,709] Trial 21 finished with value: 0.46308258734667807 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.9}. Best is trial 10 with value: 0.46308258734667807.\n",
      "[I 2025-08-10 21:22:29,036] Trial 22 finished with value: 0.46308258734667807 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.9}. Best is trial 10 with value: 0.46308258734667807.\n",
      "[I 2025-08-10 21:22:35,639] Trial 23 finished with value: 0.46308258734667807 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.9}. Best is trial 10 with value: 0.46308258734667807.\n",
      "[I 2025-08-10 21:22:42,045] Trial 24 finished with value: 0.46308258734667807 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.9}. Best is trial 10 with value: 0.46308258734667807.\n",
      "[I 2025-08-10 21:22:48,562] Trial 25 finished with value: 0.46308258734667807 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.9}. Best is trial 10 with value: 0.46308258734667807.\n",
      "[I 2025-08-10 21:22:54,950] Trial 26 finished with value: 0.46308258734667807 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.9}. Best is trial 10 with value: 0.46308258734667807.\n",
      "[I 2025-08-10 21:22:55,458] Trial 27 pruned. \n",
      "[I 2025-08-10 21:22:55,948] Trial 28 pruned. \n",
      "[I 2025-08-10 21:22:56,453] Trial 29 pruned. \n",
      "[I 2025-08-10 21:23:03,034] Trial 30 finished with value: 0.46308258734667807 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.9}. Best is trial 10 with value: 0.46308258734667807.\n",
      "[I 2025-08-10 21:23:09,496] Trial 31 finished with value: 0.46308258734667807 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.9}. Best is trial 10 with value: 0.46308258734667807.\n",
      "[I 2025-08-10 21:23:15,937] Trial 32 finished with value: 0.46308258734667807 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.9}. Best is trial 10 with value: 0.46308258734667807.\n",
      "[I 2025-08-10 21:23:22,322] Trial 33 finished with value: 0.46308258734667807 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.9}. Best is trial 10 with value: 0.46308258734667807.\n",
      "[I 2025-08-10 21:23:22,876] Trial 34 pruned. \n",
      "[I 2025-08-10 21:23:29,033] Trial 35 finished with value: 0.4651380985266547 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.85}. Best is trial 35 with value: 0.4651380985266547.\n",
      "[I 2025-08-10 21:23:29,566] Trial 36 pruned. \n",
      "[I 2025-08-10 21:23:35,719] Trial 37 finished with value: 0.4651380985266547 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.85}. Best is trial 35 with value: 0.4651380985266547.\n",
      "[I 2025-08-10 21:23:36,272] Trial 38 pruned. \n",
      "[I 2025-08-10 21:23:36,730] Trial 39 pruned. \n",
      "[I 2025-08-10 21:23:37,219] Trial 40 pruned. \n",
      "[I 2025-08-10 21:23:43,390] Trial 41 finished with value: 0.4651380985266547 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.85}. Best is trial 35 with value: 0.4651380985266547.\n",
      "[I 2025-08-10 21:23:49,622] Trial 42 finished with value: 0.4651380985266547 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.85}. Best is trial 35 with value: 0.4651380985266547.\n",
      "[I 2025-08-10 21:23:55,796] Trial 43 finished with value: 0.4651380985266547 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.85}. Best is trial 35 with value: 0.4651380985266547.\n",
      "[I 2025-08-10 21:23:56,319] Trial 44 pruned. \n",
      "[I 2025-08-10 21:24:02,522] Trial 45 finished with value: 0.4651380985266547 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.85}. Best is trial 35 with value: 0.4651380985266547.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-10 21:24:03,082] Trial 46 pruned. \n",
      "[I 2025-08-10 21:24:03,626] Trial 47 pruned. \n",
      "[I 2025-08-10 21:24:09,823] Trial 48 finished with value: 0.4651380985266547 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.85}. Best is trial 35 with value: 0.4651380985266547.\n",
      "[I 2025-08-10 21:24:10,274] Trial 49 pruned. \n",
      "[I 2025-08-10 21:24:16,549] Trial 50 finished with value: 0.4651380985266547 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.85}. Best is trial 35 with value: 0.4651380985266547.\n",
      "[I 2025-08-10 21:24:22,834] Trial 51 finished with value: 0.4651380985266547 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.85}. Best is trial 35 with value: 0.4651380985266547.\n",
      "[I 2025-08-10 21:24:29,109] Trial 52 finished with value: 0.4651380985266547 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.85}. Best is trial 35 with value: 0.4651380985266547.\n",
      "[I 2025-08-10 21:24:35,359] Trial 53 finished with value: 0.4651380985266547 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.85}. Best is trial 35 with value: 0.4651380985266547.\n",
      "[I 2025-08-10 21:24:41,607] Trial 54 finished with value: 0.4651380985266547 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.85}. Best is trial 35 with value: 0.4651380985266547.\n",
      "[I 2025-08-10 21:24:47,723] Trial 55 finished with value: 0.4651380985266547 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.85}. Best is trial 35 with value: 0.4651380985266547.\n",
      "[I 2025-08-10 21:24:48,219] Trial 56 pruned. \n",
      "[I 2025-08-10 21:24:54,451] Trial 57 finished with value: 0.4651380985266547 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.85}. Best is trial 35 with value: 0.4651380985266547.\n",
      "[I 2025-08-10 21:24:55,009] Trial 58 pruned. \n",
      "[I 2025-08-10 21:25:01,179] Trial 59 finished with value: 0.4651380985266547 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.85}. Best is trial 35 with value: 0.4651380985266547.\n",
      "[I 2025-08-10 21:25:07,420] Trial 60 finished with value: 0.4651380985266547 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.85}. Best is trial 35 with value: 0.4651380985266547.\n",
      "[I 2025-08-10 21:25:13,679] Trial 61 finished with value: 0.4651380985266547 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.85}. Best is trial 35 with value: 0.4651380985266547.\n",
      "[I 2025-08-10 21:25:19,919] Trial 62 finished with value: 0.4651380985266547 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.85}. Best is trial 35 with value: 0.4651380985266547.\n",
      "[I 2025-08-10 21:25:26,121] Trial 63 finished with value: 0.4651380985266547 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.85}. Best is trial 35 with value: 0.4651380985266547.\n",
      "[I 2025-08-10 21:25:32,363] Trial 64 finished with value: 0.4651380985266547 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.85}. Best is trial 35 with value: 0.4651380985266547.\n",
      "[I 2025-08-10 21:25:38,561] Trial 65 finished with value: 0.4651380985266547 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.85}. Best is trial 35 with value: 0.4651380985266547.\n",
      "[I 2025-08-10 21:25:44,749] Trial 66 finished with value: 0.4651380985266547 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.85}. Best is trial 35 with value: 0.4651380985266547.\n",
      "[I 2025-08-10 21:25:45,303] Trial 67 pruned. \n",
      "[I 2025-08-10 21:25:51,787] Trial 68 finished with value: 0.4651380985266547 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.85}. Best is trial 35 with value: 0.4651380985266547.\n",
      "[I 2025-08-10 21:25:52,244] Trial 69 pruned. \n",
      "[I 2025-08-10 21:25:58,446] Trial 70 finished with value: 0.4651380985266547 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.85}. Best is trial 35 with value: 0.4651380985266547.\n",
      "[I 2025-08-10 21:26:04,672] Trial 71 finished with value: 0.4651380985266547 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.85}. Best is trial 35 with value: 0.4651380985266547.\n",
      "[I 2025-08-10 21:26:10,805] Trial 72 finished with value: 0.4651380985266547 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.85}. Best is trial 35 with value: 0.4651380985266547.\n",
      "[I 2025-08-10 21:26:17,022] Trial 73 finished with value: 0.4651380985266547 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.85}. Best is trial 35 with value: 0.4651380985266547.\n",
      "[I 2025-08-10 21:26:23,219] Trial 74 finished with value: 0.4651380985266547 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.85}. Best is trial 35 with value: 0.4651380985266547.\n",
      "[I 2025-08-10 21:26:29,459] Trial 75 finished with value: 0.4651380985266547 and parameters: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.85}. Best is trial 35 with value: 0.4651380985266547.\n",
      "[I 2025-08-10 21:26:29,957] Trial 76 pruned. \n",
      "[I 2025-08-10 21:26:30,536] Trial 77 pruned. \n",
      "[I 2025-08-10 21:26:31,109] Trial 78 pruned. \n",
      "[I 2025-08-10 21:26:31,653] Trial 79 pruned. \n",
      "Best params: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.85}\n",
      "Best score: 0.4651\n"
     ]
    }
   ],
   "source": [
    "# === 8) OPTUNA TUNING ===\n",
    "\n",
    "CR_CHOICES = [0.22, 0.25, 0.28, 0.30]\n",
    "SIM_CHOICES = [0.15, 0.25, 0.35]\n",
    "DF_CHOICES = [0.85, 0.90]\n",
    "\n",
    "EVAL_INTERVAL = max(10, len(cache) // 12)\n",
    "print(f\"Tuning on {len(cache)} docs | Pruning every {EVAL_INTERVAL} docs\")\n",
    "\n",
    "def objective(trial):\n",
    "    cr = trial.suggest_categorical(\"compression_ratio\", CR_CHOICES)\n",
    "    sim = trial.suggest_categorical(\"similarity_threshold\", SIM_CHOICES)\n",
    "    df = trial.suggest_categorical(\"damping_factor\", DF_CHOICES)\n",
    "\n",
    "    scores = []\n",
    "    for i, entry in enumerate(cache, 1):\n",
    "        summary = _summary_from_cache(entry, cr, sim, df)\n",
    "        score = custom_score(summary, entry[\"doc_clean\"])\n",
    "        scores.append(score)\n",
    "\n",
    "        if i % EVAL_INTERVAL == 0:\n",
    "            trial.report(np.mean(scores), step=i)\n",
    "            if trial.should_prune():\n",
    "                raise optuna.TrialPruned()\n",
    "\n",
    "    return np.mean(scores) if scores else 0.0\n",
    "\n",
    "sampler = TPESampler(seed=RANDOM_SEED)\n",
    "pruner = MedianPruner(n_startup_trials=8, n_warmup_steps=0, interval_steps=1)\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    sampler=sampler,\n",
    "    pruner=pruner,\n",
    "    study_name=\"LexRank_M1_cached_subset\"\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=80, show_progress_bar=True)\n",
    "\n",
    "best_params = study.best_params\n",
    "best_score = float(study.best_value)\n",
    "print(\"Best params:\", best_params)\n",
    "print(\"Best score:\", round(best_score, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daee3850",
   "metadata": {},
   "source": [
    "### Best params: {'compression_ratio': 0.3, 'similarity_threshold': 0.15, 'damping_factor': 0.85}\n",
    "#### Best score: 0.4651"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461e6cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
